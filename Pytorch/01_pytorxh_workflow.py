# -*- coding: utf-8 -*-
"""01_PyTorxh_workflow.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SOz03f1g-HwCM4rADp1Lp8wr0iDXsyo-

# PyTorch workflowget

 `get data ready -> build or pick a pretrained model { u can do it by ...-> pick a loss funciton and optimizer -> build a training loop-> }-> fit the model to the data and make a prediction -> evaluate the model -> improve through experimentation -> save and reload your trained model`
"""

import torch
from torch import nn
import matplotlib.pyplot as plt


# torch.nn is a basic building block for bulding graphs

"""Creating simple dataset using linear regression

# Data  ( preparung and loading)
 Data can be almost anyting in ML

 like excel spreadsheet, images , videos , audio , DNA, Text

  ML is a game if 2 parts:
  1.Get data into a numerical representation
  2.Bild a model to learn patterns
"""

#create a known parameters

weight = 0.7
bias = 0.3

#create data

start = 0
end = 1
step = 0.02
X = torch.arange(start,end,step).unsqueeze(dim=1) # X is captial bcz it can be a matrix or a tensor
# we need unsqueeze to add a extra dimensioin ( as told by tutor )
y = weight * X + bias # formula for linear regression like y=mX+B

X[:10]  , y[:10] # length of X and y
print(f"X (only top 10): {X[:10]}") # we used [:10] to get top 10 data only like fromo first 10 data
print(f"y (only top 10): {y[:10]}")
print(f"X shape: {X.shape}")
print(f"y shape: {y.shape}")

len(X) ,len(y)

"""#Splitting our data into training and testing

#we split our data into :
1. TRAINING set which is used always to train our model it contains 60-80% of total data
2.validation set which is used often but not always contains 10-20% of total data....this set is like a practice exam set.....on which we practice to tune our model patterns...
its like ....when we learn from training data ....we give a practice exam and we doesnt do good in practivce exam......so we re-tune ourself on training data and again give the practive exam and then we do better then before....
3.Testing set which is used always to test our model it contains 10-20% of total data......here we finally test our learning model...

*Geneeralization - the basic idea is to train our model to perform well on data it hasnt seen before....like training on 70 , validating in 20 and testing on 10
"""

#lets create a train and test data with our data......lets do 80% train and 20% test

train_split = int(0.8 * len(X)) # 80% of data to train i.e train on 40 data ( 0.8 * 50 = 40 )
X_train, y_train = X[:train_split], y[:train_split] #....X_train and y_train whiich has top 40 data of X i.e 0 to 39
X_test, y_test = X[train_split:], y[train_split:] #X_test and y_test contains remaing 10 dataset as it is [40:] i.e 40 to last-1 i.e 40 to 49

#check the lenght of them

len(X_train), len(y_train), len(X_test), len(y_test) # o.p looks correcy as (40, 40, 10, 10)

"""#Building a function to visualize our data

how can we visualize our data ??
"""

def plot_predictions(train_data=X_train, # # train_data: The input data used for training the model (defaults to X_train)
                     train_labels=y_train, # train_labels: The target values corresponding to the training data (defaults to y_train)
                     test_data=X_test,
                     test_labels=y_test, # then we will get our model predict our y values based on input of X_test since its y v/s x graph...
                     predictions=None): # then to evaluate our model we can compare how well our model prediction our v/s actual values of test data set...i.e prediction v/s test_data

  # Plots training data and test dara and compare predictions

  # data is like the input data and labels are output of that data......
  # first we train the model using input data or train_data to make it learn how to achieve the output label  or train_label.....
  #then we test it on the 20% of the remaining data using TEST_DATA and it makes prediction on what the PREDICTED_TEST_LABEL could be using what it has learned in training phase
  #then we compare the PREDICTED_TEST_LABEL OR PREDICTED_TEST_OUTPUT_LABEL with the actual TEST_LABEL to check its accuracy of training.....



  plt.figure(figsize=(10, 7))
  #.figure is in matplotlib.pyplot

  # Plot training data in blue
  plt.scatter(train_data, train_labels, c="b", s=4, label="Training data") #c="b" means colour="blue"
  # s=4 means size=4

  # Plot test data in green
  plt.scatter(test_data, test_labels, c="g", s=4, label="Testing data")

  #Are there predctins ?
  if predictions is not None: # means if predictions is not none or if prediction is truethen do scatter
    # Plot predictions in red (predictions in test data)
    plt.scatter(test_data, predictions, c="r", s=4, label="Predictions")
    # scatter is a function that takes x,y values.....it for plotting a y v/s x graph ( y on vertical and x on horizontal )

#show the legend
  plt.legend(prop={"size": 14})

plot_predictions() # we got a y v/s x plot showing blue dots for training data and green for testing on remaining 20% on data we tested upon ....
#

"""# Creating our first PyTorch model

what our model does is :

* start with random values ( weight and bias )
* look at the training data and adjust the random values better to represent ( or get closer to ) the ideal values ( the weight and bias values we used to create the data )

How does it do so ?

thriugh 2 main algorithms :

1.Gradient descent
2.Backpropagation
"""

#Create a linear regression moodel class
from torch import nn # nn means neural network

#nn.Module is like lego building bricks.....base class for all neural network
class LinearRegressionModel(nn.Module):# almost everything in PyTorch inherits from nn.module....
  def __init__(self):
    super().__init__()

    #Initialize the model parameters to be used iin various computation
    self.weights = nn.Parameter(torch.randn(1, #<- start with a random weight value and try to adjust it to th ideal weight
                                           requires_grad=True,# by default it is still True ,we told that the value can be updated via gradient descent
                                           dtype=torch.float))

    # gradient descent is the reason for  requires_grad being true as when we run computation using this model .....PyTorch will get record of the gradient of weights and bias
    #and then update them using gradient descent

    self.bias  = nn.Parameter(torch.randn(1,#<- start with a random bias value and try to adjust it to th ideal bias
                                           requires_grad=True,# by default it is still True , we told that the value can be updated via gradient descent
                                           dtype=torch.float))

    # we could have wrote
    # self.weights = nn.Parameter(torch.randn(1))
    # self.bias = nn.Parameter(torch.randn(1))

    #forward method to define the computation in the model
  def forward(self, x:torch.tensor) -> torch.tensor: # <- "x " is the input data or the training data
      return self.weights * x + self.bias # this is the linear reg formula

"""#PyTorch model building essentials

*torch.nn - contains a ll of the building bloocks for computational graphs ( a neural network)
*torch.nn.Parameter - what parameyters should our model trya nd learn often a pytorch layer from torch,nn will set this for us
*torch.nn.Module - the base class for all nneura; modules , if u subclass it , u should overwrite the forward() ( function)
*torch.otpim - used to perform optimization the values to better fit the data , generally useful with gradient descent
*def foraward() - all nn.Module subclass requres u to overwrite rthe forward() , this method defines what happens in forward computational

#checking the contents of our pytorch model

so we can check our model parameters or what is inside our model using `.parameters()`
"""

#create a random seed

torch.manual_seed(42)

#create an instance of the model ( this is rthe subclass of nn.Module)

model_0 = LinearRegressionModel()
model_0

list(model_0.parameters())

#List named parameters
model_0.state_dict()

weight , bias
# the whole ppoint of ML is start from random value and update our value closer to IDEAL VALUEs

"""# making prediction using `torch.inference_mode()`

to check our models predictive power, lets see how well it predicts `y_test` based on `X_test`

when we passs data through our model , its going to run it through the `forward()` methiod
"""

X_test , y_test

#Make predictions with model

with torch.inference_mode(): # it traxks less data in backebd which makes predictoin faster....
  y_preds = model_0(X_test) # we pass the X_test data into our model_0......and perfectly prefectly return the values of y_test

y_preds # shit the value it agve was horrible ðŸ˜‚  , now its time to update the values so that the prediction can be more accurate such that the red dots can overlap green dots

plot_predictions(predictions = y_preds)

"""One way to measure how poor or how wrong our model is predicting is using the LOSS FUNCTION.

Loss function can also nbe called cost function

**Loss function ** : A function to measure how wromg your model's prediction are to the ideal outputs , the lowrr the better

**Optimizer** : Take into account the loss of a model and adjusts the parameters ( eg.  weight and bias ) to imporve the loss function

And specifically for PyTorch , we need â‰
* A training loop
* A testing loop
"""

list(model_0.parameters())

model_0.state_dict()

#Setup a loss function

loss_fn = nn.L1Loss()
# it will detect how poor our model is working

#setup an optimizer
# bascially a stochastic gradient descent optimizing algoritm used to optimize it for now
optimizer = torch.optim.SGD(params=model_0.parameters() ,
                            lr = 0.01 # lr basically is learning rate = possobly most important hyper paramter we can set ourselves....its default value is 0.1....
                            #the higher the lr the more the parameters will be adjusted in 1 hit or each hit.....means it will increase or dec by 0.1 as i get it
                            )
#it will optimize all the parameters to make rhe loss lower
# the use of optimiser and loss funcition is question specefic

"""#Building a training loop and a testing loop

Things we need to do in training loop :

0.Loop through the data.

1.forward pass ( this involves data moving through our models `forward()`){its like data moving from Inout to Output layer in the nueral network model }
also called forawrd propogation

2. calculate the loss compare forward pass predictions tp ground truth labels

3.optimizer zero grad

4.loss backwards -  move backwards ...i.e from o.p to i.p.....to calculate the gradient of each of the parameter of our model with respect to the loss(**backpropogation**)


5.optimizer step - use the optimizwr to adjust our models parameters to try and improve the loss.(**gradient descent**)
gradient is bascialy slope ......can be 2D and 3D.....we want to move our gradient to 0 so that loss can become 0 too.....
"""

list(model_0.parameters())

# an epoch is one loop through the data ( this is a hyperparameter bcz we set it ourselves)
epochs = 100

#Training loop
# 0. loop through the data....
for epochs in range(epochs):

  #so we actuallly training the model on training data to predict the training label
  #then calculating the loss in prediction and optimizing it untill we get best results
  # .......then we test the model on unseen data

  #set the model to training mode
  model_0.train()

  #1.forward pass
  y_pred = model_0(X_train)
  #y(pred) = X_train * w + b ,  w= weight and b = bias....the y_pred will give us the TRAIN_LABEL or Predicted Train_label.....
  # it means we train our model on seen data to predict the TRAIN_label then we compare this predicted train label with actual train label
  # then we compare the loss and then optimize it accordingly......then we test this model on unseen data and perform the prediction on test label
  #then we plot the graph

  # 2. calculate the loss
  loss = loss_fn(y_pred , y_train) #output = loss_funciton(input , target)
  # it compares the y_pred to the actual values i.e y_train using a loss fnctiom
  print(f"loss : { loss }")
  #3.optimiser zero grad or zero the grad to avoid accumulation of grad
  optimizer.zero_grad()

  #4. perform backpropogatio on the loss wrt the parameters of the model
  loss.backward()

  # 5.step the optimizer ( perform gradient descent)
  optimizer.step() # by default the optimizer will acculmulate through the looop so...we have to zero the grad above in step 3 for the next iteration of the loop

  #TESTING
  model_0.eval()  # puting the model in evaluatioin mode
  with torch.inference_mode(): # tursn off a couple of things  happening in backend to make it faster

    #1. DO the forward pass
    test_pred = model_0(X_test)
    #now we want the PREDICTED_TEST_LABEL using the Test_data

    # 2.Calculate the loss
    test_loss= loss_fn(test_pred,y_test)
    #we then calculate the test loss which is actually the difference in PREDICTED_TEST_LABEL AND ACTUAL_TEST_LABEL

    #print out whats happening

  if epochs % 10 ==0: # print what is happening in every 10 epochs
      print(f"{epochs } | Loss : {loss} | Test loss :{test_loss}")

      #print out the model state_dict()
      print(model_0.state_dict())
      #model_0.state_dict() reflects the current state of the modelâ€™s parameters (weights and biases) at the time it is called. Let's dive deeper into what it represents and whether it is the "best" value:

# Yes, model_0.state_dict() reflects the current state of the modelâ€™s parameters (weights and biases) at the time it is called. Let's dive deeper into what it represents and whether it is the "best" value:

# What is model_0.state_dict()?
# It is a Python dictionary that contains the current values of all learnable parameters (like weights and biases) and sometimes other information (like running statistics in BatchNorm layers).
# Example:
# python
# Copy
# Edit
# model_0.state_dict()
# Output:
# plaintext
# Copy
# Edit
# {
#     'linear.weight': tensor([[0.3367]], requires_grad=True),
#     'linear.bias': tensor([0.1288], requires_grad=True)
# }
# Does it Represent the Best Values?
# During Training
# Not necessarily the "best" yet:
# When you call model_0.state_dict() during training, it shows the current state of the parameters.
# As the training progresses, these values get updated by the optimizer to reduce the loss.
# The parameters might not yet represent the "best" model until training is complete.
# After Training
# Can represent the best values:
# If training is done properly (with appropriate loss minimization, learning rate, etc.), the state_dict will contain the parameters that produce the best results on the training data.
# However, to evaluate the "best" parameters for unseen data, you'd test it on the test dataset.

with torch.inference_mode():
  y_preds_new = model_0(X_test)

plot_predictions(predictions = y_preds_new)
# i got this bcz i runned the above big code approx 10 or more times to get least loss of 0.07 but also reached 0.018
# i will then set epochs for 100

""" #Save the pytorch model"""

from pathlib import Path

#1. create models directory


MODEL_PATH = Path("models")
MODEL_PATH.mkdir(parents=True , exist_ok = True)

#2. Create model save Path

MODEL_NAME = "01_PyTorch_workflow.pth"
MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME
MODEL_SAVE_PATH

#3. save the model state dict

print(f"Saving model to :  { MODEL_SAVE_PATH}")
torch.save(obj=model_0.state_dict(),
           f=MODEL_SAVE_PATH)

"""#Code to load the model in pytorch

since we saved our models state_dict() instead of whole model ,we will create a new instance of our mode; class and load the saved state_dict()
"""

#To load in a saved state_dict() we have to instantiate a new instance of our model class

loaded_model_0 = LinearRegressionModel()

#load the saved state_dict() of model_0 ( this will update the new instave with updated parameters)

loaded_model_0

loaded_model_0.load_state_dict(torch.load(f=MODEL_SAVE_PATH))

loaded_model_0.state_dict()

loaded_model_0.eval()
with torch.inference_mode():
  loaded_model_0_preds = loaded_model_0(X_test)

y_preds_new == loaded_model_0_preds

"""# create device-agnostic code.

thsi means if we have got access to a gpu , our code will use it

if no gpu available , the code will use cpu
"""

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"using devices : { device }")